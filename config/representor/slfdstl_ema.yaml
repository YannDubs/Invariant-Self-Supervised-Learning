# @package _global_
defaults:
  - slfdstl

representor:
  name: slfdstl_mlp

decodability:
  kwargs:
    is_ema: False
    is_process_Mx: False
    is_stop_grad:  True
    is_pred_proj_same:  False
    beta_H_mlz: null # currently, not using because KL should take care of minimizing entropy
    mode_pMlz_qMlz: "KL"
    beta_pM_unif: 1.0 # TODO: tune
    ema_weight_prior: 0.05 # TODO: tune
    queue_size: 0 # TODO: tune
    predictor_kwargs:
      architecture: "linear"
      out_shape: 128
    projector_kwargs:
      architecture: "mlp"
      hid_dim: 2048
      n_hid_layers: 2
      norm_layer: "batch"
      out_shape: ${decodability.kwargs.predictor_kwargs.out_shape}
