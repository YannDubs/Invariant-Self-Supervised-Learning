
[[36m2021-10-20 00:39:00,308[39m][[34m__main__[39m][[32mINFO[39m] - Train representor ...
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Epoch 0:   0%|                                                   | 0/13 [00:00<00:00, 554.14it/s]
   | Name                                      | Type                        | Params
-------------------------------------------------------------------------------------------
0  | p_ZlX                                     | CondDist                    | 11.2 M
1  | p_ZlX.mapper                              | ResNet                      | 11.2 M
2  | p_ZlX.mapper.resnet                       | ResNet                      | 11.2 M
3  | p_ZlX.mapper.resnet.conv1                 | Conv2d                      | 576
4  | p_ZlX.mapper.resnet.bn1                   | BatchNorm2d                 | 128
5  | p_ZlX.mapper.resnet.relu                  | ReLU                        | 0
6  | p_ZlX.mapper.resnet.maxpool               | Identity                    | 0
7  | p_ZlX.mapper.resnet.layer1                | Sequential                  | 147 K
8  | p_ZlX.mapper.resnet.layer1.0              | BasicBlock                  | 74.0 K
9  | p_ZlX.mapper.resnet.layer1.0.conv1        | Conv2d                      | 36.9 K
10 | p_ZlX.mapper.resnet.layer1.0.bn1          | BatchNorm2d                 | 128
11 | p_ZlX.mapper.resnet.layer1.0.relu         | ReLU                        | 0
12 | p_ZlX.mapper.resnet.layer1.0.conv2        | Conv2d                      | 36.9 K
13 | p_ZlX.mapper.resnet.layer1.0.bn2          | BatchNorm2d                 | 128
14 | p_ZlX.mapper.resnet.layer1.1              | BasicBlock                  | 74.0 K
15 | p_ZlX.mapper.resnet.layer1.1.conv1        | Conv2d                      | 36.9 K
16 | p_ZlX.mapper.resnet.layer1.1.bn1          | BatchNorm2d                 | 128
17 | p_ZlX.mapper.resnet.layer1.1.relu         | ReLU                        | 0
18 | p_ZlX.mapper.resnet.layer1.1.conv2        | Conv2d                      | 36.9 K
19 | p_ZlX.mapper.resnet.layer1.1.bn2          | BatchNorm2d                 | 128
20 | p_ZlX.mapper.resnet.layer2                | Sequential                  | 525 K
21 | p_ZlX.mapper.resnet.layer2.0              | BasicBlock                  | 230 K
22 | p_ZlX.mapper.resnet.layer2.0.conv1        | Conv2d                      | 73.7 K
23 | p_ZlX.mapper.resnet.layer2.0.bn1          | BatchNorm2d                 | 256
24 | p_ZlX.mapper.resnet.layer2.0.relu         | ReLU                        | 0
25 | p_ZlX.mapper.resnet.layer2.0.conv2        | Conv2d                      | 147 K
26 | p_ZlX.mapper.resnet.layer2.0.bn2          | BatchNorm2d                 | 256
27 | p_ZlX.mapper.resnet.layer2.0.downsample   | Sequential                  | 8.4 K
28 | p_ZlX.mapper.resnet.layer2.0.downsample.0 | Conv2d                      | 8.2 K
29 | p_ZlX.mapper.resnet.layer2.0.downsample.1 | BatchNorm2d                 | 256
30 | p_ZlX.mapper.resnet.layer2.1              | BasicBlock                  | 295 K
31 | p_ZlX.mapper.resnet.layer2.1.conv1        | Conv2d                      | 147 K
32 | p_ZlX.mapper.resnet.layer2.1.bn1          | BatchNorm2d                 | 256
33 | p_ZlX.mapper.resnet.layer2.1.relu         | ReLU                        | 0
34 | p_ZlX.mapper.resnet.layer2.1.conv2        | Conv2d                      | 147 K
35 | p_ZlX.mapper.resnet.layer2.1.bn2          | BatchNorm2d                 | 256
36 | p_ZlX.mapper.resnet.layer3                | Sequential                  | 2.1 M
37 | p_ZlX.mapper.resnet.layer3.0              | BasicBlock                  | 919 K
38 | p_ZlX.mapper.resnet.layer3.0.conv1        | Conv2d                      | 294 K
39 | p_ZlX.mapper.resnet.layer3.0.bn1          | BatchNorm2d                 | 512
40 | p_ZlX.mapper.resnet.layer3.0.relu         | ReLU                        | 0
41 | p_ZlX.mapper.resnet.layer3.0.conv2        | Conv2d                      | 589 K
42 | p_ZlX.mapper.resnet.layer3.0.bn2          | BatchNorm2d                 | 512
43 | p_ZlX.mapper.resnet.layer3.0.downsample   | Sequential                  | 33.3 K
44 | p_ZlX.mapper.resnet.layer3.0.downsample.0 | Conv2d                      | 32.8 K
45 | p_ZlX.mapper.resnet.layer3.0.downsample.1 | BatchNorm2d                 | 512
46 | p_ZlX.mapper.resnet.layer3.1              | BasicBlock                  | 1.2 M
47 | p_ZlX.mapper.resnet.layer3.1.conv1        | Conv2d                      | 589 K
48 | p_ZlX.mapper.resnet.layer3.1.bn1          | BatchNorm2d                 | 512
49 | p_ZlX.mapper.resnet.layer3.1.relu         | ReLU                        | 0
50 | p_ZlX.mapper.resnet.layer3.1.conv2        | Conv2d                      | 589 K
51 | p_ZlX.mapper.resnet.layer3.1.bn2          | BatchNorm2d                 | 512
52 | p_ZlX.mapper.resnet.layer4                | Sequential                  | 8.4 M
53 | p_ZlX.mapper.resnet.layer4.0              | BasicBlock                  | 3.7 M
54 | p_ZlX.mapper.resnet.layer4.0.conv1        | Conv2d                      | 1.2 M
55 | p_ZlX.mapper.resnet.layer4.0.bn1          | BatchNorm2d                 | 1.0 K
56 | p_ZlX.mapper.resnet.layer4.0.relu         | ReLU                        | 0
57 | p_ZlX.mapper.resnet.layer4.0.conv2        | Conv2d                      | 2.4 M
58 | p_ZlX.mapper.resnet.layer4.0.bn2          | BatchNorm2d                 | 1.0 K
59 | p_ZlX.mapper.resnet.layer4.0.downsample   | Sequential                  | 132 K
60 | p_ZlX.mapper.resnet.layer4.0.downsample.0 | Conv2d                      | 131 K
61 | p_ZlX.mapper.resnet.layer4.0.downsample.1 | BatchNorm2d                 | 1.0 K
62 | p_ZlX.mapper.resnet.layer4.1              | BasicBlock                  | 4.7 M
63 | p_ZlX.mapper.resnet.layer4.1.conv1        | Conv2d                      | 2.4 M
64 | p_ZlX.mapper.resnet.layer4.1.bn1          | BatchNorm2d                 | 1.0 K
65 | p_ZlX.mapper.resnet.layer4.1.relu         | ReLU                        | 0
66 | p_ZlX.mapper.resnet.layer4.1.conv2        | Conv2d                      | 2.4 M
67 | p_ZlX.mapper.resnet.layer4.1.bn2          | BatchNorm2d                 | 1.0 K
68 | p_ZlX.mapper.resnet.avgpool               | AdaptiveAvgPool2d           | 0
69 | p_ZlX.mapper.resnet.fc                    | Linear                      | 65.7 K
70 | Z_processor                               | Identity                    | 0
71 | loss_decodability                         | ClusterSelfDistillationISSL | 400 K
72 | loss_decodability.predictor               | FlattenLinear               | 16.5 K
73 | loss_decodability.Mx_logits               | Linear                      | 384 K
74 | loss_regularizer                          | CoarseningRegularizer       | 0
75 | evaluator                                 | OnlineEvaluator             | 4.5 M
76 | evaluator.model                           | FlattenMLP                  | 4.5 M
77 | evaluator.model.pre_block                 | Sequential                  | 266 K
78 | evaluator.model.pre_block.0               | Linear                      | 262 K
79 | evaluator.model.pre_block.1               | BatchNorm1d                 | 4.1 K
80 | evaluator.model.pre_block.2               | ReLU                        | 0
81 | evaluator.model.pre_block.3               | Identity                    | 0
82 | evaluator.model.hidden_block              | Sequential                  | 4.2 M
83 | evaluator.model.hidden_block.0            | Linear                      | 4.2 M
84 | evaluator.model.hidden_block.1            | BatchNorm1d                 | 4.1 K
85 | evaluator.model.hidden_block.2            | ReLU                        | 0
86 | evaluator.model.hidden_block.3            | Identity                    | 0
87 | evaluator.model.post_block                | Linear                      | 20.5 K
-------------------------------------------------------------------------------------------
16.1 M    Trainable params
0         Non-trainable params
16.1 M    Total params
64.476    Total estimated model params size (MB)
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:12<00:00,  1.09it/s, loss=5.4, v_num=8-51]


Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  4.06it/s, loss=5.14, v_num=8-51]


Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:03<00:00,  3.72it/s, loss=5.14, v_num=8-51]

Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.37it/s, loss=5.14, v_num=8-51]
Saving latest checkpoint...
> /atlas/u/yanndubs/ISSL/main.py(104)main()
-> save_pretrained(repr_cfg, repr_trainer, stage)

(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(116)main()
-> if repr_cfg.evaluation.representor.is_evaluate:
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(117)main()
-> logger.info("Evaluate compressor ...")
(Pdb) n
[[36m2021-10-20 00:43:58,444[39m][[34m__main__[39m][[32mINFO[39m] - Evaluate compressor ...
> /atlas/u/yanndubs/ISSL/main.py(118)main()
-> repr_res = evaluate(repr_trainer, repr_datamodule, repr_cfg, stage)
(Pdb) n
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91it/s]
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:678: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test/repr/beta': 1.0,
 'test/repr/decodability': 8.121394157409668,
 'test/repr/eval_acc': 0.109375,
 'test/repr/eval_err': 0.890625,
 'test/repr/eval_loss': 2.830190658569336,
 'test/repr/fit_pMlz_qMlz': 8.121394157409668,
 'test/repr/loss': 8.177770614624023,
 'test/repr/regularize': 0.05637681484222412}
--------------------------------------------------------------------------------
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.07s/it]
[[36m2021-10-20 00:44:02,251[39m][[34m__main__[39m][[32mINFO[39m] - Logging results to /atlas/u/yanndubs/ISSL/results/exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_cluster_self_distillation/enc_resnet18/reg_cosine/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/jid_None_2021-10-20_00-38-51/results_representor.csv.
> /atlas/u/yanndubs/ISSL/main.py(122)main()
-> finalize_stage_(
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(123)main()
-> stage,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(124)main()
-> repr_cfg,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(125)main()
-> representor,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(126)main()
-> repr_trainer,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(127)main()
-> repr_datamodule,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(128)main()
-> repr_res,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(129)main()
-> finalize_kwargs,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(130)main()
-> is_save_best=True,
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(122)main()
-> finalize_stage_(
(Pdb) n
[[36m2021-10-20 00:44:19,982[39m][[34m__main__[39m][[32mINFO[39m] - Finalizing representor.
> /atlas/u/yanndubs/ISSL/main.py(132)main()
-> if repr_cfg.predictor.is_skip:
(Pdb) repr_cfg.predictor.is_skip
False
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(135)main()
-> del repr_datamodule  # not used anymore and can be large

(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(138)main()
-> if repr_cfg.representor.is_on_the_fly:
(Pdb) repr_cfg.representor.is_on_the_fly
True

(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(140)main()
-> on_fly_representor = representor
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(141)main()
-> pre_representor = None
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(148)main()
-> logger.info("Stage : Predictor")
(Pdb) n
[[36m2021-10-20 00:44:45,518[39m][[34m__main__[39m][[32mINFO[39m] - Stage : Predictor
> /atlas/u/yanndubs/ISSL/main.py(149)main()
-> stage = "predictor"
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(150)main()
-> pred_cfg = set_cfg(cfg, stage)
(Pdb) n
[[36m2021-10-20 00:44:48,684[39m][[34m__main__[39m][[32mINFO[39m] - Name : exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_cluster_self_distillation/enc_resnet18/reg_cosine/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/datapred_mnist/augpred_rotation_scale_shear_x-translation_y-translation//optpred_AdamW_lr3.0e-04_w1.0e-05/schedpred_unifmultistep100/addpred_None.
> /atlas/u/yanndubs/ISSL/main.py(151)main()
-> pred_datamodule = instantiate_datamodule_(pred_cfg, pre_representor=pre_representor)
(Pdb) pre_representor

(Pdb) n
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
> /atlas/u/yanndubs/ISSL/main.py(152)main()
-> pred_cfg = omegaconf2namespace(pred_cfg)
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(154)main()
-> if pred_cfg.predictor.is_train and not is_trained(pred_cfg, stage):



(Pdb) is_trained(repr_cfg, "representor")
True
(Pdb) n
(Pdb)
(Pdb) is_trained(pred_cfg, stage)
(Pdb) ns_trained(pred_cfg, stage)
(Pdb) not pred_cfg.predictor.is_sklearn:n()
(Pdb) pred_cfg.predictor.is_sklearnearn:n()
(Pdb) pred_cfg.predictor.is_sklearnearn:n()
> /atlas/u/yanndubs/ISSL/main.py(157)main()
> /atlas/u/yanndubs/ISSL/main.py(157)main()
-> predictor = Predictor(hparams=pred_cfg, representor=on_fly_representor)
(Pdb) pred_
(Pdb) pred_cf
(Pdb) pred_cfg.data.target_is_clf
          (0): BasicBlock(ce=True)
        (maxpool): Identity()
        (layer1): Sequential(
          (0): BasicBlock(ce=True)
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (layer4): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): BasicBlock(
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
        (fc): Linear(in_features=512, out_features=128, bias=True)
      )
    )
  )
  (Z_processor): Identity()
  (loss_decodability): ClusterSelfDistillationISSL(
    (predictor): FlattenLinear(in_features=128, out_features=128, bias=True)
    (projector): FlattenLinear(in_features=128, out_features=128, bias=True)
    (Mx_logits): Linear(in_features=128, out_features=3000, bias=False)
  )
  (loss_regularizer): CoarseningRegularizer()
  (evaluator): OnlineEvaluator(
    (model): FlattenMLP(
      (pre_block): Sequential(
        (0): Linear(in_features=128, out_features=2048, bias=False)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Identity()
      )
      (hidden_block): Sequential(
        (0): Linear(in_features=2048, out_features=2048, bias=False)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Identity()
      )
      (post_block): Linear(in_features=2048, out_features=10, bias=True)
    )
  )
)
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
(Pdb) on_fly_representor.set_represent_mode_
Error executing job with overrides: ['mode=dev', 'data_repr.kwargs.num_workers=2', 'regularizer=cosine', 'decodability=cluster_self_distillation', 'experiment=dev']
(Pdb) on_fly_representor.set_represent_mode_
Traceback (most recent call last):
  File "/atlas/u/yanndubs/ISSL/main.py", line 157, in main
    pred_trainer = get_trainer(pred_cfg, predictor, is_representor=False)
  File "/atlas/u/yanndubs/ISSL/issl/predictors.py", line 47, in __init__
    if representor is not None:
  File "/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'ISSLModule' object has no attribute 'out_shape'
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
(Pdb) on_fly_representor.set_represent_mode_