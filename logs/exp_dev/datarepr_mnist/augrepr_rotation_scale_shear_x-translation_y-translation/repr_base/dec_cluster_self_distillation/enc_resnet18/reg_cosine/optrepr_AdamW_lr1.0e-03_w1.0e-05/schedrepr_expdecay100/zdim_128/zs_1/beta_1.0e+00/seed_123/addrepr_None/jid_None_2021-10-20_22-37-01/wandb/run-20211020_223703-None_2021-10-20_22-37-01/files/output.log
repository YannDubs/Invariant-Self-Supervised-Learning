
[[36m2021-10-20 22:37:11,345[39m][[34m__main__[39m][[32mINFO[39m] - Train representor ...
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Epoch 0:   0%|                                                  | 0/13 [00:00<00:00, 1014.59it/s]
   | Name                                      | Type                        | Params
-------------------------------------------------------------------------------------------
0  | p_ZlX                                     | CondDist                    | 11.2 M
1  | p_ZlX.mapper                              | ResNet                      | 11.2 M
2  | p_ZlX.mapper.resnet                       | ResNet                      | 11.2 M
3  | p_ZlX.mapper.resnet.conv1                 | Conv2d                      | 576
4  | p_ZlX.mapper.resnet.bn1                   | BatchNorm2d                 | 128
5  | p_ZlX.mapper.resnet.relu                  | ReLU                        | 0
6  | p_ZlX.mapper.resnet.maxpool               | Identity                    | 0
7  | p_ZlX.mapper.resnet.layer1                | Sequential                  | 147 K
8  | p_ZlX.mapper.resnet.layer1.0              | BasicBlock                  | 74.0 K
9  | p_ZlX.mapper.resnet.layer1.0.conv1        | Conv2d                      | 36.9 K
10 | p_ZlX.mapper.resnet.layer1.0.bn1          | BatchNorm2d                 | 128
11 | p_ZlX.mapper.resnet.layer1.0.relu         | ReLU                        | 0
12 | p_ZlX.mapper.resnet.layer1.0.conv2        | Conv2d                      | 36.9 K
13 | p_ZlX.mapper.resnet.layer1.0.bn2          | BatchNorm2d                 | 128
14 | p_ZlX.mapper.resnet.layer1.1              | BasicBlock                  | 74.0 K
15 | p_ZlX.mapper.resnet.layer1.1.conv1        | Conv2d                      | 36.9 K
16 | p_ZlX.mapper.resnet.layer1.1.bn1          | BatchNorm2d                 | 128
17 | p_ZlX.mapper.resnet.layer1.1.relu         | ReLU                        | 0
18 | p_ZlX.mapper.resnet.layer1.1.conv2        | Conv2d                      | 36.9 K
19 | p_ZlX.mapper.resnet.layer1.1.bn2          | BatchNorm2d                 | 128
20 | p_ZlX.mapper.resnet.layer2                | Sequential                  | 525 K
21 | p_ZlX.mapper.resnet.layer2.0              | BasicBlock                  | 230 K
22 | p_ZlX.mapper.resnet.layer2.0.conv1        | Conv2d                      | 73.7 K
23 | p_ZlX.mapper.resnet.layer2.0.bn1          | BatchNorm2d                 | 256
24 | p_ZlX.mapper.resnet.layer2.0.relu         | ReLU                        | 0
25 | p_ZlX.mapper.resnet.layer2.0.conv2        | Conv2d                      | 147 K
26 | p_ZlX.mapper.resnet.layer2.0.bn2          | BatchNorm2d                 | 256
27 | p_ZlX.mapper.resnet.layer2.0.downsample   | Sequential                  | 8.4 K
28 | p_ZlX.mapper.resnet.layer2.0.downsample.0 | Conv2d                      | 8.2 K
29 | p_ZlX.mapper.resnet.layer2.0.downsample.1 | BatchNorm2d                 | 256
30 | p_ZlX.mapper.resnet.layer2.1              | BasicBlock                  | 295 K
31 | p_ZlX.mapper.resnet.layer2.1.conv1        | Conv2d                      | 147 K
32 | p_ZlX.mapper.resnet.layer2.1.bn1          | BatchNorm2d                 | 256
33 | p_ZlX.mapper.resnet.layer2.1.relu         | ReLU                        | 0
34 | p_ZlX.mapper.resnet.layer2.1.conv2        | Conv2d                      | 147 K
35 | p_ZlX.mapper.resnet.layer2.1.bn2          | BatchNorm2d                 | 256
36 | p_ZlX.mapper.resnet.layer3                | Sequential                  | 2.1 M
37 | p_ZlX.mapper.resnet.layer3.0              | BasicBlock                  | 919 K
38 | p_ZlX.mapper.resnet.layer3.0.conv1        | Conv2d                      | 294 K
39 | p_ZlX.mapper.resnet.layer3.0.bn1          | BatchNorm2d                 | 512
40 | p_ZlX.mapper.resnet.layer3.0.relu         | ReLU                        | 0
41 | p_ZlX.mapper.resnet.layer3.0.conv2        | Conv2d                      | 589 K
42 | p_ZlX.mapper.resnet.layer3.0.bn2          | BatchNorm2d                 | 512
43 | p_ZlX.mapper.resnet.layer3.0.downsample   | Sequential                  | 33.3 K
44 | p_ZlX.mapper.resnet.layer3.0.downsample.0 | Conv2d                      | 32.8 K
45 | p_ZlX.mapper.resnet.layer3.0.downsample.1 | BatchNorm2d                 | 512
46 | p_ZlX.mapper.resnet.layer3.1              | BasicBlock                  | 1.2 M
47 | p_ZlX.mapper.resnet.layer3.1.conv1        | Conv2d                      | 589 K
48 | p_ZlX.mapper.resnet.layer3.1.bn1          | BatchNorm2d                 | 512
49 | p_ZlX.mapper.resnet.layer3.1.relu         | ReLU                        | 0
50 | p_ZlX.mapper.resnet.layer3.1.conv2        | Conv2d                      | 589 K
51 | p_ZlX.mapper.resnet.layer3.1.bn2          | BatchNorm2d                 | 512
52 | p_ZlX.mapper.resnet.layer4                | Sequential                  | 8.4 M
53 | p_ZlX.mapper.resnet.layer4.0              | BasicBlock                  | 3.7 M
54 | p_ZlX.mapper.resnet.layer4.0.conv1        | Conv2d                      | 1.2 M
55 | p_ZlX.mapper.resnet.layer4.0.bn1          | BatchNorm2d                 | 1.0 K
56 | p_ZlX.mapper.resnet.layer4.0.relu         | ReLU                        | 0
57 | p_ZlX.mapper.resnet.layer4.0.conv2        | Conv2d                      | 2.4 M
58 | p_ZlX.mapper.resnet.layer4.0.bn2          | BatchNorm2d                 | 1.0 K
59 | p_ZlX.mapper.resnet.layer4.0.downsample   | Sequential                  | 132 K
60 | p_ZlX.mapper.resnet.layer4.0.downsample.0 | Conv2d                      | 131 K
61 | p_ZlX.mapper.resnet.layer4.0.downsample.1 | BatchNorm2d                 | 1.0 K
62 | p_ZlX.mapper.resnet.layer4.1              | BasicBlock                  | 4.7 M
63 | p_ZlX.mapper.resnet.layer4.1.conv1        | Conv2d                      | 2.4 M
64 | p_ZlX.mapper.resnet.layer4.1.bn1          | BatchNorm2d                 | 1.0 K
65 | p_ZlX.mapper.resnet.layer4.1.relu         | ReLU                        | 0
66 | p_ZlX.mapper.resnet.layer4.1.conv2        | Conv2d                      | 2.4 M
67 | p_ZlX.mapper.resnet.layer4.1.bn2          | BatchNorm2d                 | 1.0 K
68 | p_ZlX.mapper.resnet.avgpool               | AdaptiveAvgPool2d           | 0
69 | p_ZlX.mapper.resnet.fc                    | Linear                      | 65.7 K
70 | Z_processor                               | Identity                    | 0
71 | loss_decodability                         | ClusterSelfDistillationISSL | 400 K
72 | loss_decodability.predictor               | FlattenLinear               | 16.5 K
73 | loss_decodability.Mx_logits               | Linear                      | 384 K
74 | loss_regularizer                          | CoarseningRegularizer       | 0
75 | evaluator                                 | OnlineEvaluator             | 4.5 M
76 | evaluator.model                           | FlattenMLP                  | 4.5 M
77 | evaluator.model.pre_block                 | Sequential                  | 266 K
78 | evaluator.model.pre_block.0               | Linear                      | 262 K
79 | evaluator.model.pre_block.1               | BatchNorm1d                 | 4.1 K
80 | evaluator.model.pre_block.2               | ReLU                        | 0
81 | evaluator.model.pre_block.3               | Identity                    | 0
82 | evaluator.model.hidden_block              | Sequential                  | 4.2 M
83 | evaluator.model.hidden_block.0            | Linear                      | 4.2 M
84 | evaluator.model.hidden_block.1            | BatchNorm1d                 | 4.1 K
85 | evaluator.model.hidden_block.2            | ReLU                        | 0
86 | evaluator.model.hidden_block.3            | Identity                    | 0
87 | evaluator.model.post_block                | Linear                      | 20.5 K
-------------------------------------------------------------------------------------------
16.1 M    Trainable params
0         Non-trainable params
16.1 M    Total params
64.476    Total estimated model params size (MB)
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:13<00:00,  1.05it/s, loss=5.44, v_num=7-01]


Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.92it/s, loss=5.12, v_num=7-01]


Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.93it/s, loss=5.09, v_num=7-01]
Epoch 2, global step 32: val/repr/loss was not in top 1

Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  2.02it/s, loss=5.09, v_num=7-01]
[[36m2021-10-20 22:38:27,198[39m][[34m__main__[39m][[32mINFO[39m] - Saved best checkpoint to /atlas/u/yanndubs/ISSL/pretrained/exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_cluster_self_distillation/enc_resnet18/reg_cosine/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/jid_None_2021-10-20_22-37-01/best_representor.ckpt.
[[36m2021-10-20 22:38:27,200[39m][[34m__main__[39m][[32mINFO[39m] - Evaluate representor ...
Testing: 0it [00:00, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.59it/s]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test/repr/beta': 1.0,
 'test/repr/decodability': 8.133975982666016,
 'test/repr/eval_acc': 0.109375,
 'test/repr/eval_err': 0.890625,
 'test/repr/eval_loss': 2.891842842102051,
 'test/repr/fit_pMlz_qMlz': 8.133975982666016,
 'test/repr/loss': 8.150765419006348,
 'test/repr/regularize': 0.016789915040135384}
--------------------------------------------------------------------------------
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.91it/s]
[[36m2021-10-20 22:38:28,606[39m][[34m__main__[39m][[32mINFO[39m] - Logging results to /atlas/u/yanndubs/ISSL/results/exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_cluster_self_distillation/enc_resnet18/reg_cosine/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/jid_None_2021-10-20_22-37-01/results_representor.csv.
[[36m2021-10-20 22:38:28,607[39m][[34m__main__[39m][[32mINFO[39m] - Finalizing representor.
[[36m2021-10-20 22:38:28,819[39m][[34m__main__[39m][[32mINFO[39m] - Stage : Predictor
[[36m2021-10-20 22:38:28,853[39m][[34m__main__[39m][[32mINFO[39m] - Name : exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_cluster_self_distillation/enc_resnet18/reg_cosine/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/datapred_mnist/pred_sk_svm/optpred_AdamW_lr3.0e-04_w1.0e-05/schedpred_unifmultistep100/addpred_None.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:376: UserWarning: Your predict_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.
  rank_zero_warn(
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Predicting: 11it [00:00, ?it/s]
Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 891/891 [00:11<00:00, 73.78it/s]
Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 45.97it/s]
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.
  rank_zero_deprecation(
Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 40.44it/s]
Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:02<00:00, 63.05it/s]
> /atlas/u/yanndubs/ISSL/main.py(155)main()
-> is_sklearn = pred_cfg.predictor.is_sklearn

(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(156)main()
-> if pred_cfg.predictor.is_train and not is_trained(pred_cfg, stage):
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(157)main()
-> if is_sklearn:
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(158)main()
-> assert not repr_cfg.representor.is_on_the_fly
(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(159)main()
-> predictor = SklearnPredictor(pred_cfg)
(Pdb) SklearnPredictor(pred_cfg)
SklearnPredictor(cfg=NamespaceMap(experiment='dev', job_id='None_2021-10-20_22-37-01', seed=123, timeout=60, time='None_2021-10-20_22-37-01', long_name_repr='exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_cluster_self_distillation/enc_resnet18/reg_cosine/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay10...ceMap(architecture='flatten', out_shape=128), n_Mx=3000, freeze_Mx_epochs=1, src_tgt_comparison='symmetric', temperature=0.1, queue_size=30, sinkhorn_kwargs=NamespaceMap(eps=0.05))), regularizer=NamespaceMap(name='cosine', factor_beta=1, kwargs=NamespaceMap(loss='cosine', mode='coarsener', is_aux_already_represented=False)), finetune=NamespaceMap(name='none')))

(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(160)main()
-> pred_trainer = SklearnTrainer(pred_cfg.predictor)
(Pdb) s
--Call--
> /atlas/u/yanndubs/ISSL/utils/helpers.py(242)__init__()
-> def __init__(self, scores: Union[str, Sequence[str]]):
(Pdb) n
> /atlas/u/yanndubs/ISSL/utils/helpers.py(243)__init__()
-> self.model = None
(Pdb) n
> /atlas/u/yanndubs/ISSL/utils/helpers.py(244)__init__()
-> self.stage = None
(Pdb) n
> /atlas/u/yanndubs/ISSL/utils/helpers.py(245)__init__()
-> if isinstance(scores, str):
(Pdb) l
240  	    """Wrapper around sklearn that mimics pytorch lightning trainer."""
241  	
242  	    def __init__(self, scores: Union[str, Sequence[str]]):
243  	        self.model = None
244  	        self.stage = None
245  ->	        if isinstance(scores, str):
246  	            scores = [scores]
247  	        self.scores = [getattr(sklearn.metrics, s) for s in scores]
248  	
249  	    def fit(self, model: Pipeline, datamodule: SklearnDataModule):
250  	        data = datamodule.train_dataset
(Pdb) scores
NamespaceMap(name='sk_svm', is_skip=False, is_train=True, kwargs=NamespaceMap(arch_kwargs=NamespaceMap(hid_dim=2048, norm_layer='batchnorm', n_hid_layers=2, activation='ReLU', dropout_p=0.0), architecture='mlp'), is_sklearn=True, is_scale=False, scaler=NamespaceMap(_target_='sklearn.preprocessing.StandardScaler'), metrics=['accuracy_score', 'balanced_accuracy_score'], model=NamespaceMap(_target_='sklearn.svm.LinearSVC', dual=False, C=1, class_weight=None, random_state=123))







(Pdb) !scores=["accuracy_score","balanced_accuracy_score"]
(Pdb) scores
['accuracy_score', 'balanced_accuracy_score']
(Pdb) l
251  	        model.fit(data.X, data.Y)
252  	        self.model = model
253  	
254  	    def save_checkpoint(self, ckpt_path: Union[str, Path], _):
255  	        dump(self.model, ckpt_path)
256  	
257  	    def test(
258  	        self, dataloaders: DataLoader, ckpt_path: Union[str, Path]
259  	    ) -> dict[str, float]:
260  	        data = dataloaders.dataset
261  	        if ckpt_path is not None:
(Pdb) n
> /atlas/u/yanndubs/ISSL/utils/helpers.py(247)__init__()
-> self.scores = [getattr(sklearn.metrics, s) for s in scores]
(Pdb) n
--Return--
> /atlas/u/yanndubs/ISSL/utils/helpers.py(247)__init__()->None
-> self.scores = [getattr(sklearn.metrics, s) for s in scores]

(Pdb) self.scores
[<function accuracy_score at 0x7f954c57e160>, <function balanced_accuracy_score at 0x7f954c57e9d0>]

(Pdb) n
> /atlas/u/yanndubs/ISSL/main.py(165)main()
-> logger.info("Train predictor ...")
(Pdb) l
160  	            pred_trainer = SklearnTrainer(pred_cfg.predictor)
161  	        else:
162  	            predictor = Predictor(hparams=pred_cfg, representor=on_fly_representor)
163  	            pred_trainer = get_trainer(pred_cfg, predictor, is_representor=False)
164  	
165  ->	        logger.info("Train predictor ...")
166  	        pred_trainer.fit(predictor, datamodule=pred_datamodule)
167  	        save_pretrained(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
168  	
169  	    else:
170  	        logger.info("Load pretrained predictor ...")
(Pdb) n
[[36m2021-10-20 22:41:52,438[39m][[34m__main__[39m][[32mINFO[39m] - Train predictor ...
> /atlas/u/yanndubs/ISSL/main.py(166)main()
-> pred_trainer.fit(predictor, datamodule=pred_datamodule)
(Pdb)
> /atlas/u/yanndubs/ISSL/utils/helpers.py(250)fit()
-> data = datamodule.train_dataset
(Pdb)
> /atlas/u/yanndubs/ISSL/utils/helpers.py(250)fit()
> /atlas/u/yanndubs/ISSL/utils/helpers.py(250)fit()
> /atlas/u/yanndubs/ISSL/utils/helpers.py(250)fit()
(Pdb) data.X.shapes/ISSL/utils/helpers.py(250)fit()
(Pdb) data.X.shapes/ISSL/utils/helpers.py(250)fit()
(Pdb) data.Y.shapes/ISSL/utils/helpers.py(250)fit()
(Pdb) data.Y.shapes/ISSL/utils/helpers.py(250)fit()
(Pdb) data.Y.shapes/ISSL/utils/helpers.py(250)fit()
(Pdb) data.Y.shapes/ISSL/utils/helpers.py(250)fit()
(Pdb) data.Y.shapes/ISSL/utils/helpers.py(250)fit()
(Pdb)     def fit(self, model: Pipeline, datamodule: SklearnDataModule):
(Pdb) m   def fit(self, model: Pipeline, datamodule: SklearnDataModule):
(Pdb) modelef fit(self, model: Pipeline, datamodule: SklearnDataModule):
(Pdb) modelef fit(self, model: Pipeline, datamodule: SklearnDataModule):
(Pdb) model["model]elf, model: Pipeline, datamodule: SklearnDataModule):
(Pdb) model["model]elf, model: Pipeline, datamodule: SklearnDataModule):
(Pdb) model["model"]lf, model: Pipeline, datamodule: SklearnDataModule):
266  	            for score in self.scoresatamodule: SklearnDataModule):
-> save_pretrained(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
169  	    else:ned(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
169  	    else:ned(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
169  	    else:ned(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
169  	  _sklearned(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
169  	  _sklearned(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
(Pdb) n _sklearned(pred_cfg, pred_trainer, stage, is_sklearn=is_sklearn)
493  ->	    trainer.save_checkpoint(ckpt_path, weights_only=True)klearn)
-> trainer.save_checkpoint(ckpt_path, weights_only=True)nly=True)klearn)
-> trainer.save_checkpoint(ckpt_path, weights_only=True)nly=True)klearn)
-> trainer.save_checkpoint(ckpt_path, weights_only=True)nly=True)klearn)
-> tranner.save_checkpoint(ckpt_path, weights_only=True)nly=True)klearn)
-> tranner.save_checkpoint(ckpt_path, weights_only=True)nly=True)klearn)
-> traquit()ave_checkpoint(ckpt_path, weights_only=True)nly=True)klearn)
