
Testing: 0it [00:00, ?it/s]
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.22s/it]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{'test/repr/I_q_zm': 1.2050845623016357,
 'test/repr/beta': 9.999999747378752e-06,
 'test/repr/decodability': 5.031284809112549,
 'test/repr/eval_acc': 0.119140625,
 'test/repr/eval_err': 0.880859375,
 'test/repr/eval_loss': 2.5886335372924805,
 'test/repr/hat_H_m': 6.236369609832764,
 'test/repr/loss': 5.031284809112549,
 'test/repr/n_negatives': 511.0,
 'test/repr/regularize': 0.0}
--------------------------------------------------------------------------------
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.32s/it]
[[36m2021-10-20 18:13:56,559[39m][[34m__main__[39m][[32mINFO[39m] - Logging results to /atlas/u/yanndubs/ISSL/results/exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_contrastive/enc_resnet18/reg_none/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/jid_None_2021-10-20_18-12-52/results_representor.csv.
[[36m2021-10-20 18:13:56,561[39m][[34m__main__[39m][[32mINFO[39m] - Finalizing representor.
[[36m2021-10-20 18:13:56,721[39m][[34m__main__[39m][[32mINFO[39m] - Stage : Predictor
[[36m2021-10-20 18:13:56,761[39m][[34m__main__[39m][[32mINFO[39m] - Name : exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_contrastive/enc_resnet18/reg_none/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/datapred_mnist/pred_mlp_h2048_l2/optpred_AdamW_lr3.0e-04_w1.0e-05/schedpred_unifmultistep100/addpred_None.
Using native 16bit precision.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
   | Name                                                  | Type              | Params
---------------------------------------------------------------------------------------------
0  | representor                                           | ISSLModule        | 0
1  | representor.p_ZlX                                     | CondDist          | 0
2  | representor.p_ZlX.mapper                              | ResNet            | 0
3  | representor.p_ZlX.mapper.resnet                       | ResNet            | 0
4  | representor.p_ZlX.mapper.resnet.conv1                 | Conv2d            | 0
5  | representor.p_ZlX.mapper.resnet.bn1                   | BatchNorm2d       | 0
6  | representor.p_ZlX.mapper.resnet.relu                  | ReLU              | 0
7  | representor.p_ZlX.mapper.resnet.maxpool               | Identity          | 0
8  | representor.p_ZlX.mapper.resnet.layer1                | Sequential        | 0
9  | representor.p_ZlX.mapper.resnet.layer1.0              | BasicBlock        | 0
10 | representor.p_ZlX.mapper.resnet.layer1.0.conv1        | Conv2d            | 0
11 | representor.p_ZlX.mapper.resnet.layer1.0.bn1          | BatchNorm2d       | 0
12 | representor.p_ZlX.mapper.resnet.layer1.0.relu         | ReLU              | 0
13 | representor.p_ZlX.mapper.resnet.layer1.0.conv2        | Conv2d            | 0
14 | representor.p_ZlX.mapper.resnet.layer1.0.bn2          | BatchNorm2d       | 0
15 | representor.p_ZlX.mapper.resnet.layer1.1              | BasicBlock        | 0
16 | representor.p_ZlX.mapper.resnet.layer1.1.conv1        | Conv2d            | 0
17 | representor.p_ZlX.mapper.resnet.layer1.1.bn1          | BatchNorm2d       | 0
18 | representor.p_ZlX.mapper.resnet.layer1.1.relu         | ReLU              | 0
19 | representor.p_ZlX.mapper.resnet.layer1.1.conv2        | Conv2d            | 0
20 | representor.p_ZlX.mapper.resnet.layer1.1.bn2          | BatchNorm2d       | 0
21 | representor.p_ZlX.mapper.resnet.layer2                | Sequential        | 0
22 | representor.p_ZlX.mapper.resnet.layer2.0              | BasicBlock        | 0
23 | representor.p_ZlX.mapper.resnet.layer2.0.conv1        | Conv2d            | 0
24 | representor.p_ZlX.mapper.resnet.layer2.0.bn1          | BatchNorm2d       | 0
25 | representor.p_ZlX.mapper.resnet.layer2.0.relu         | ReLU              | 0
26 | representor.p_ZlX.mapper.resnet.layer2.0.conv2        | Conv2d            | 0
27 | representor.p_ZlX.mapper.resnet.layer2.0.bn2          | BatchNorm2d       | 0
28 | representor.p_ZlX.mapper.resnet.layer2.0.downsample   | Sequential        | 0
29 | representor.p_ZlX.mapper.resnet.layer2.0.downsample.0 | Conv2d            | 0
30 | representor.p_ZlX.mapper.resnet.layer2.0.downsample.1 | BatchNorm2d       | 0
31 | representor.p_ZlX.mapper.resnet.layer2.1              | BasicBlock        | 0
32 | representor.p_ZlX.mapper.resnet.layer2.1.conv1        | Conv2d            | 0
33 | representor.p_ZlX.mapper.resnet.layer2.1.bn1          | BatchNorm2d       | 0
34 | representor.p_ZlX.mapper.resnet.layer2.1.relu         | ReLU              | 0
35 | representor.p_ZlX.mapper.resnet.layer2.1.conv2        | Conv2d            | 0
36 | representor.p_ZlX.mapper.resnet.layer2.1.bn2          | BatchNorm2d       | 0
37 | representor.p_ZlX.mapper.resnet.layer3                | Sequential        | 0
38 | representor.p_ZlX.mapper.resnet.layer3.0              | BasicBlock        | 0
39 | representor.p_ZlX.mapper.resnet.layer3.0.conv1        | Conv2d            | 0
40 | representor.p_ZlX.mapper.resnet.layer3.0.bn1          | BatchNorm2d       | 0
41 | representor.p_ZlX.mapper.resnet.layer3.0.relu         | ReLU              | 0
42 | representor.p_ZlX.mapper.resnet.layer3.0.conv2        | Conv2d            | 0
43 | representor.p_ZlX.mapper.resnet.layer3.0.bn2          | BatchNorm2d       | 0
44 | representor.p_ZlX.mapper.resnet.layer3.0.downsample   | Sequential        | 0
45 | representor.p_ZlX.mapper.resnet.layer3.0.downsample.0 | Conv2d            | 0
46 | representor.p_ZlX.mapper.resnet.layer3.0.downsample.1 | BatchNorm2d       | 0
47 | representor.p_ZlX.mapper.resnet.layer3.1              | BasicBlock        | 0
48 | representor.p_ZlX.mapper.resnet.layer3.1.conv1        | Conv2d            | 0
49 | representor.p_ZlX.mapper.resnet.layer3.1.bn1          | BatchNorm2d       | 0
50 | representor.p_ZlX.mapper.resnet.layer3.1.relu         | ReLU              | 0
51 | representor.p_ZlX.mapper.resnet.layer3.1.conv2        | Conv2d            | 0
52 | representor.p_ZlX.mapper.resnet.layer3.1.bn2          | BatchNorm2d       | 0
53 | representor.p_ZlX.mapper.resnet.layer4                | Sequential        | 0
54 | representor.p_ZlX.mapper.resnet.layer4.0              | BasicBlock        | 0
55 | representor.p_ZlX.mapper.resnet.layer4.0.conv1        | Conv2d            | 0
56 | representor.p_ZlX.mapper.resnet.layer4.0.bn1          | BatchNorm2d       | 0
57 | representor.p_ZlX.mapper.resnet.layer4.0.relu         | ReLU              | 0
58 | representor.p_ZlX.mapper.resnet.layer4.0.conv2        | Conv2d            | 0
59 | representor.p_ZlX.mapper.resnet.layer4.0.bn2          | BatchNorm2d       | 0
60 | representor.p_ZlX.mapper.resnet.layer4.0.downsample   | Sequential        | 0
61 | representor.p_ZlX.mapper.resnet.layer4.0.downsample.0 | Conv2d            | 0
62 | representor.p_ZlX.mapper.resnet.layer4.0.downsample.1 | BatchNorm2d       | 0
63 | representor.p_ZlX.mapper.resnet.layer4.1              | BasicBlock        | 0
64 | representor.p_ZlX.mapper.resnet.layer4.1.conv1        | Conv2d            | 0
65 | representor.p_ZlX.mapper.resnet.layer4.1.bn1          | BatchNorm2d       | 0
66 | representor.p_ZlX.mapper.resnet.layer4.1.relu         | ReLU              | 0
67 | representor.p_ZlX.mapper.resnet.layer4.1.conv2        | Conv2d            | 0
68 | representor.p_ZlX.mapper.resnet.layer4.1.bn2          | BatchNorm2d       | 0
69 | representor.p_ZlX.mapper.resnet.avgpool               | AdaptiveAvgPool2d | 0
70 | representor.p_ZlX.mapper.resnet.fc                    | Linear            | 0
71 | representor.Z_processor                               | Identity          | 0
72 | representor.loss_decodability                         | ContrastiveISSL   | 0
73 | representor.loss_decodability.predictor               | FlattenLinear     | 0
74 | representor.evaluator                                 | OnlineEvaluator   | 0
75 | representor.evaluator.model                           | FlattenMLP        | 0
[[36m2021-10-20 18:13:59,292[39m][[34m__main__[39m][[32mINFO[39m] - Train predictor ...
Epoch 0:   0%|                                                  | 0/26 [00:00<00:00, 2843.60it/s]
76 | representor.evaluator.model.pre_block                 | Sequential        | 0
77 | representor.evaluator.model.pre_block.0               | Linear            | 0
78 | representor.evaluator.model.pre_block.1               | BatchNorm1d       | 0
79 | representor.evaluator.model.pre_block.2               | ReLU              | 0
80 | representor.evaluator.model.pre_block.3               | Identity          | 0
81 | representor.evaluator.model.hidden_block              | Sequential        | 0
82 | representor.evaluator.model.hidden_block.0            | Linear            | 0
83 | representor.evaluator.model.hidden_block.1            | BatchNorm1d       | 0
84 | representor.evaluator.model.hidden_block.2            | ReLU              | 0
85 | representor.evaluator.model.hidden_block.3            | Identity          | 0
86 | representor.evaluator.model.post_block                | Linear            | 0
87 | predictor                                             | FlattenMLP        | 4.5 M
88 | predictor.pre_block                                   | Sequential        | 266 K
89 | predictor.pre_block.0                                 | Linear            | 262 K
90 | predictor.pre_block.1                                 | BatchNorm1d       | 4.1 K
91 | predictor.pre_block.2                                 | ReLU              | 0
92 | predictor.pre_block.3                                 | Identity          | 0
93 | predictor.hidden_block                                | Sequential        | 4.2 M
94 | predictor.hidden_block.0                              | Linear            | 4.2 M
95 | predictor.hidden_block.1                              | BatchNorm1d       | 4.1 K
96 | predictor.hidden_block.2                              | ReLU              | 0
97 | predictor.hidden_block.3                              | Identity          | 0
98 | predictor.post_block                                  | Linear            | 20.5 K
---------------------------------------------------------------------------------------------
4.5 M     Trainable params
0         Non-trainable params
4.5 M     Total params
17.941    Total estimated model params size (MB)
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/sailhome/yanndubs/anaconda3/envs/issl/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(



Epoch 2:   0%|                           | 0/26 [00:00<00:00, 1036.65it/s, loss=2.16, v_num=2-52]

Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00, 18.54it/s, loss=1.96, v_num=2-52]

Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00,  9.32it/s, loss=1.96, v_num=2-52]
Saving latest checkpoint...
Error executing job with overrides: ['mode=dev', 'data_repr.kwargs.num_workers=2', 'experiment=dev', 'representor.is_train=False', 'paths.pretrained.load=/atlas/u/yanndubs/ISSL/pretrained/exp_dev/datarepr_mnist/augrepr_rotation_scale_shear_x-translation_y-translation/repr_base/dec_contrastive/enc_resnet18/reg_none/optrepr_AdamW_lr1.0e-03_w1.0e-05/schedrepr_expdecay100/zdim_128/zs_1/beta_1.0e+00/seed_123/addrepr_None/jid_None_2021-10-20_17-56-29', 'evaluation.representor.is_evaluate=True']
Traceback (most recent call last):
  File "/atlas/u/yanndubs/ISSL/main.py", line 168, in main
    save_pretrained(pred_cfg, pred_trainer, stage)
TypeError: save_pretrained() missing 1 required positional argument: 'is_sklearn'
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.