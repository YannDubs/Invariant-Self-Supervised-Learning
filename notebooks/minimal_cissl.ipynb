{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interim-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning==1.7.2 in /usr/local/lib/python3.8/dist-packages (1.7.2)\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.10.0)\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning==1.7.2 scikit-learn==1.0.2 lightning-bolts=0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-teacher",
   "metadata": {},
   "source": [
    "Basic variables depending on whether using GPU or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caring-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_dir = \"data/\"\n",
    "if torch.cuda.is_available():\n",
    "    device, precision, gpus = \"cuda\", 16, 1\n",
    "else:\n",
    "    device, precision, gpus = \"cpu\", 32, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-sacrifice",
   "metadata": {},
   "source": [
    "## CISSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suitable-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "class CISSL(pl.LightningModule):\n",
    "    \"\"\"CISSL objective.\"\"\"\n",
    "\n",
    "    def __init__(self, proj_dim=128, temperature=0.07, max_epochs=100):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # ENCODER\n",
    "        self.encoder = resnet18()\n",
    "        self.encoder.fc = nn.Identity() # remove last linear layer\n",
    "        z_dim=512\n",
    "        \n",
    "        # TEACHER PROJECTION HEAD\n",
    "        # more expressive is better => MLP\n",
    "        n_hidden = 2048\n",
    "        bottleneck_size = 512 # adds a bottleneck to avoid linear layer with many parameters\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(z_dim, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_hidden, bottleneck_size),\n",
    "            nn.BatchNorm1d(bottleneck_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(bottleneck_size, proj_dim),\n",
    "            nn.BatchNorm1d(proj_dim) # for contrastive learning batchnorm is typically added\n",
    "        )\n",
    "        \n",
    "        # STUDENT PROJECTION HEAD: \n",
    "        # needs to be linear (batchnorm is)\n",
    "        self.predictor = nn.Sequential(nn.Linear(z_dim, proj_dim),\n",
    "                                       nn.BatchNorm1d(proj_dim))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x1, x2 = batch\n",
    "        bs, device = x1.size(0), x1.device\n",
    "        \n",
    "        # shape: [2*batch_size, z_dim]\n",
    "        z = self.encoder(torch.cat([x1, x2], dim=0))\n",
    "        \n",
    "        # shape: [2*batch_size, proj_dim]\n",
    "        # normalize to use cosine similarity\n",
    "        z_student = F.normalize(self.predictor(z), dim=1, p=2)\n",
    "        z_teacher = F.normalize(self.projector(z), dim=1, p=2)\n",
    "        \n",
    "        # shape: [2*batch_size, 2*batch_size]\n",
    "        logits = (z_student @ z_teacher.T).float() / self.hparams.temperature\n",
    "        \n",
    "        # there are two positives for each example x1: x1 and x2\n",
    "        # note: SimCLR removes x1-x1 as those are typically equal. \n",
    "        # But not for CISSL due to asymmetric proj heads\n",
    "        # => computes cross entropy between predicted proba of positives and 0.5 for each positive\n",
    "        predicted_log_q = logits.log_softmax(-1)\n",
    "        select_positives = torch.eye(bs, device=device).bool().repeat(2, 2) \n",
    "        cross_entropy = - predicted_log_q[select_positives].view(bs*2, 2).sum(1) / 2 \n",
    "        \n",
    "        return cross_entropy.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self(batch) \n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        return self.encoder(x).cpu().numpy(), y.cpu().numpy()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=2e-3, weight_decay=1e-6)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-stone",
   "metadata": {},
   "source": [
    "## Data\n",
    "Downloads and prepare the necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "least-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "pretrain_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=96, scale=(0.2, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "champion-naples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "class PretrainSTL10(STL10):\n",
    "    def __init__(self, data_dir, pretrain_transforms, download=True):\n",
    "        super().__init__(data_dir, download=download, split=\"unlabeled\", transform=None)\n",
    "        self.pretrain_transforms = pretrain_transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x,y = super().__getitem__(index)\n",
    "        x1 = self.pretrain_transforms(x)\n",
    "        x2 = self.pretrain_transforms(x)\n",
    "        return x1, x2\n",
    "\n",
    "data_pretrain = PretrainSTL10(data_dir, pretrain_transforms=pretrain_transforms, download=True)\n",
    "data_train = STL10(data_dir,  split=\"train\", transform=val_transforms, download=True)\n",
    "data_test = STL10(data_dir, split=\"test\", transform=val_transforms, download=True)\n",
    "\n",
    "loader_pretrain = DataLoader(data_pretrain, batch_size=256, shuffle=True,\n",
    "                               num_workers=os.cpu_count(), pin_memory=True)\n",
    "loader_train = DataLoader(data_train, batch_size=512, shuffle=False, num_workers=os.cpu_count(),\n",
    "                          pin_memory=True, drop_last=False)\n",
    "loader_test = DataLoader(data_train, batch_size=512, shuffle=False, num_workers=os.cpu_count(),\n",
    "                         pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-matrix",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "junior-contents",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | ResNet     | 11.2 M\n",
      "1 | projector | Sequential | 2.2 M \n",
      "2 | predictor | Sequential | 65.9 K\n",
      "-----------------------------------------\n",
      "13.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.4 M    Total params\n",
      "26.826    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2596b50eb0f0460193f6aa72c7046ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "cissl= CISSL(max_epochs=EPOCHS)\n",
    "trainer = pl.Trainer(gpus=gpus, precision=precision, max_epochs=EPOCHS, logger=False, enable_checkpointing=False)\n",
    "trainer.fit(cissl, train_dataloaders=loader_pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-carry",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "determined-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82f4dff307b4e38a6085029fd080c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 391it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f02a478a9644f2b033216b30f2926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 391it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Z_train, Y_train = zip(*trainer.predict(dataloaders=loader_train, model=cissl))\n",
    "Z_test, Y_test = zip(*trainer.predict(dataloaders=loader_test, model=cissl))\n",
    "\n",
    "Z_train = np.concatenate(Z_train, axis=0)\n",
    "Y_train = np.concatenate(Y_train, axis=0)\n",
    "Z_test = np.concatenate(Z_test, axis=0)\n",
    "Y_test = np.concatenate(Y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "religious-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downstream STL10 accuracy: 95.36%\n"
     ]
    }
   ],
   "source": [
    "# Downstream evaluation. Accuracy: 95.36%\n",
    "from sklearn.svm import LinearSVC\n",
    "import tqdm\n",
    "\n",
    "best_acc = 0\n",
    "for C in tqdm.tqdm(np.logspace(-3,0,base=10,num=7)):\n",
    "    clf = LinearSVC(C=C)\n",
    "    clf.fit(Z_train, Y_train)\n",
    "    acc = clf.score(Z_test, Y_test)\n",
    "    best_acc = max(best_acc, acc)\n",
    "print(f\"Downstream STL10 accuracy: {best_acc*100:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-administrator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}